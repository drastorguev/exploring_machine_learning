{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Import libraries.\n",
    "import math\n",
    "import os\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Define some constants.\n",
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size. Must be evenly dividable by dataset sizes.\n",
    "BATCH_SIZE = 100\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "# Number of units in hidden layers.\n",
    "HIDDEN1_UNITS = 128\n",
    "HIDDEN2_UNITS = 32\n",
    "\n",
    "# Maximum number of training steps.\n",
    "MAX_STEPS = 2000\n",
    "\n",
    "# Directory to put the training data.\n",
    "TRAIN_DIR=\"/tmp/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Get input data: get the sets of images and labels for training, validation, and\n",
    "# test on MNIST.\n",
    "data_sets = read_data_sets(TRAIN_DIR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Build inference graph.\n",
    "def mnist_inference(images, hidden1_units, hidden2_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder.\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([IMAGE_PIXELS, hidden1_units],\n",
    "                                stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]),\n",
    "                             name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "    # Hidden 2\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden1_units, hidden2_units],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden1_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]),\n",
    "                             name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden2_units, NUM_CLASSES],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden2_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]),\n",
    "                             name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"inference.pbtxt\", as_text=True)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Build training graph.\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    \"\"\"Build the training graph.\n",
    "\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES].\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values in the\n",
    "          range [0, NUM_CLASSES).\n",
    "        learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The Op for calculating loss.\n",
    "    \"\"\"\n",
    "    # Create an operation that calculates loss.\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"train.pbtxt\", as_text=True)\n",
    "\n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Build the complete graph for feeding inputs, training, and saving checkpoints.\n",
    "mnist_graph = tf.Graph()\n",
    "with mnist_graph.as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder = tf.placeholder(tf.float32)                                       \n",
    "    labels_placeholder = tf.placeholder(tf.int32)\n",
    "    tf.add_to_collection(\"images\", images_placeholder)  # Remember this Op.\n",
    "    tf.add_to_collection(\"labels\", labels_placeholder)  # Remember this Op.\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist_inference(images_placeholder,\n",
    "                             HIDDEN1_UNITS,\n",
    "                             HIDDEN2_UNITS)\n",
    "    tf.add_to_collection(\"logits\", logits)  # Remember this Op.\n",
    "\n",
    "    # Add to the Graph the Ops that calculate and apply gradients.\n",
    "    train_op, loss = mnist_training(logits, labels_placeholder, 0.01)\n",
    "\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"complete.pbtxt\", as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.31\n",
      "Step 1000: loss = 0.52\n"
     ]
    }
   ],
   "source": [
    "# 2.7 Run training for MAX_STEPS and save checkpoint at the end.\n",
    "with tf.Session(graph=mnist_graph) as sess:\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the training loop.\n",
    "    for step in xrange(MAX_STEPS):\n",
    "        # Read a batch of images and labels.\n",
    "        images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "        # Run one step of the model.  The return values are the activations\n",
    "        # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "        # inspect the values of your Ops or variables, you may include them\n",
    "        # in the list passed to sess.run() and the value tensors will be\n",
    "        # returned in the tuple from the call.\n",
    "        _, loss_value = sess.run([train_op, loss],\n",
    "                                 feed_dict={images_placeholder: images_feed,\n",
    "                                            labels_placeholder: labels_feed})\n",
    "\n",
    "        # Print out loss value.\n",
    "        if step % 1000 == 0:\n",
    "            print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "\n",
    "    # Write a checkpoint.\n",
    "    checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mnist/checkpoint-1999\n",
      "Ground truth: 8\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiAowg8ERfiBoAg/ENT/AZuOVn6IDeo6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ba43d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.8 Run evaluation based on the saved checkpoint.\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    saver = tf.train.import_meta_graph(\n",
    "        os.path.join(TRAIN_DIR, \"checkpoint-1999.meta\"))\n",
    "    saver.restore(\n",
    "        sess, os.path.join(TRAIN_DIR, \"checkpoint-1999\"))\n",
    "\n",
    "    # Retrieve the Ops we 'remembered'.\n",
    "    logits = tf.get_collection(\"logits\")[0]\n",
    "    images_placeholder = tf.get_collection(\"images\")[0]\n",
    "    labels_placeholder = tf.get_collection(\"labels\")[0]\n",
    "    \n",
    "    # Add an Op that chooses the top k predictions.\n",
    "    eval_op = tf.nn.top_k(logits)\n",
    "    \n",
    "    # Run evaluation.\n",
    "    images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "    imgplot = plt.imshow(np.reshape(images_feed, (28, 28)))\n",
    "    prediction = sess.run(eval_op,\n",
    "                          feed_dict={images_placeholder: images_feed,\n",
    "                                     labels_placeholder: labels_feed})\n",
    "    print(\"Ground truth: %d\\nPrediction: %d\" % (labels_feed, prediction.indices[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
